# Task 3: Predictive Analytics - Breast Cancer Dataset

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Load dataset
data = pd.read_csv('breast_cancer_data.csv')  # Update this if needed

# 2. Preprocessing
# Drop ID column
data = data.drop(['id'], axis=1)

# Encode 'diagnosis': M = malignant = high, B = benign = low
data['diagnosis'] = data['diagnosis'].map({'M': 'high', 'B': 'low'})

# Optionally convert to numeric labels
priority_map = {'low': 0, 'high': 2}
data['priority'] = data['diagnosis'].map(priority_map)

# Drop original diagnosis if needed
data = data.drop(['diagnosis'], axis=1)

# 3. Split data
X = data.drop('priority', axis=1)
y = data['priority']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4. Train Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 5. Predict & Evaluate
y_pred = model.predict(X_test)

acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='macro')

print("Accuracy:", acc)
print("F1 Score:", f1)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# 6. Visualize feature importance
importances = pd.Series(model.feature_importances_, index=X.columns)
importances.nlargest(10).plot(kind='barh')
plt.title('Top 10 Feature Importances')
plt.show()
